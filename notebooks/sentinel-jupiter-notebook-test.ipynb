{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dc47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinel_lake.providers import MicrosoftSentinelProvider\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType, LongType\n",
    "\n",
    "data_provider = MicrosoftSentinelProvider(spark)\n",
    "table_name = 'PurviewDataSensitivityLogs'\n",
    "workspace_name = 'BOND-2-Log-Analytics'\n",
    "data = data_provider.read_table(table_name, workspace_name)\n",
    "\n",
    "# Target table\n",
    "unique_purview_table = \"UniquePurviewTable_SPRK\"\n",
    "\n",
    "# Delete existing table if needed\n",
    "# try:\n",
    "#     data_provider.delete_table(unique_purview_table, \"default\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting existing table: {e}\")\n",
    "\n",
    "# Read existing table if present\n",
    "try:\n",
    "    existing_table = data_provider.read_table(unique_purview_table, \"default\")\n",
    "except Exception:\n",
    "    existing_table = None\n",
    "\n",
    "# Window for row_number per AssetPath (latest per asset)\n",
    "window_spec = Window.partitionBy(\"AssetPath\").orderBy(F.col(\"TimeGenerated\").desc())\n",
    "\n",
    "# UDF to sort array safely\n",
    "def sort_array_safe(arr):\n",
    "    if arr is None:\n",
    "        return []\n",
    "    return sorted([str(x) for x in arr])\n",
    "\n",
    "sort_array_udf = F.udf(sort_array_safe, ArrayType(StringType()))\n",
    "\n",
    "# Filter valid records\n",
    "distinct_records = data.filter(\n",
    "    (F.col(\"Classification\").isNotNull()) &\n",
    "    (~F.col(\"Classification\").isin(\"\", \"[]\")) &           # remove empty arrays stored as strings\n",
    "    (F.col(\"ClassificationDetails\").isNotNull()) &\n",
    "    (F.length(F.col(\"ClassificationDetails\")) > 2) &\n",
    "    (F.col(\"TimeGenerated\") >= F.expr(\"current_timestamp() - interval 1440 hours\")) &\n",
    "    (F.col(\"ActivityType\") == \"Classification\") &\n",
    "    (F.col(\"AssetType\").isin(\"File\", \"Table\"))\n",
    ") \\\n",
    ".withColumn(\"row_num\", F.row_number().over(window_spec)) \\\n",
    ".filter(F.col(\"row_num\") == 1) \\\n",
    ".filter(~F.col(\"AssetPath\").contains(\"#\")) \\\n",
    ".withColumn(\"Classification_sorted\", sort_array_udf(F.col(\"Classification\"))) \\\n",
    ".withColumn(\n",
    "    \"id\",\n",
    "    F.sha2(\n",
    "        F.concat_ws(\"|\", F.col(\"AssetPath\"), F.concat_ws(\",\", F.col(\"Classification_sorted\"))),\n",
    "        256\n",
    "    )\n",
    ") \\\n",
    ".select(\n",
    "    F.col(\"AssetPath\"),\n",
    "    F.col(\"Classification\"),\n",
    "    F.col(\"ClassificationDetails\"),\n",
    "    F.col(\"TimeGenerated\"),\n",
    "    F.col(\"id\"),\n",
    "    F.col(\"AssetPath\").alias(\"ExternalID\"),\n",
    "    F.col(\"SourceName\"),\n",
    "    F.col(\"SourceType\"),\n",
    "    F.col(\"SourceRegion\"),\n",
    "    F.col(\"AssetName\"),\n",
    "    F.col(\"AssetType\"),\n",
    "    F.col(\"ItOwner\") if \"ItOwner\" in data.columns else F.lit(\"none@na.com\").alias(\"ItOwner\")\n",
    ")\n",
    "\n",
    "# Remove duplicates already in the target table\n",
    "if existing_table:\n",
    "    distinct_records = distinct_records.join(\n",
    "        existing_table.select(\"id\").alias(\"existing\"),\n",
    "        on=\"id\",\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "\n",
    "# Determine last RowID\n",
    "if existing_table is not None and \"RowID\" in existing_table.columns:\n",
    "    last_rowid = existing_table.agg(F.max(\"RowID\").alias(\"max_rowid\")).collect()[0][\"max_rowid\"] or 0\n",
    "else:\n",
    "    last_rowid = 0\n",
    "\n",
    "# Assign sequential RowID that continues from last saved record\n",
    "rowid_window = Window.orderBy(F.col(\"TimeGenerated\").asc())\n",
    "distinct_records = distinct_records.withColumn(\n",
    "    \"RowID\",\n",
    "    (F.row_number().over(rowid_window) + F.lit(last_rowid)).cast(LongType())\n",
    ")\n",
    "\n",
    "# Show sample\n",
    "distinct_records.show(10, False)\n",
    "\n",
    "# Save records\n",
    "record_count = distinct_records.count()\n",
    "print(\"new_record_count:\", record_count)\n",
    "\n",
    "write_options = {'mode': 'append'}\n",
    "if record_count > 0:\n",
    "    data_provider.save_as_table(distinct_records, unique_purview_table, 'default', write_options)\n",
    "    print(f\"Appended {record_count} new records to {unique_purview_table}.\")\n",
    "else:\n",
    "    print(\"No new records to append. Table is already up-to-date.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'BOND-2-Log-Analytics' # to read from a specific workspace\n",
    "df = data_provider.read_table(unique_purview_table)\n",
    "df.show(100, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "small pool (4 vCores) [sentinel-jupiter-notebook-test]",
   "language": "Python",
   "name": "MSGSmall"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
